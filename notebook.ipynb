{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8c9Im4BMmdSi",
        "collapsed": true,
        "outputId": "8cd12cd7-1a89-4daa-a378-5641aa291e72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-ik8d2xze\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-ik8d2xze\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=fa4616c58f795e9fdc557b3b1d59a710130c2c568b8c3fa0547d0c0cc030a511\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cozi05dr/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: ftfy, clip\n",
            "Successfully installed clip-1.0 ftfy-6.3.1\n",
            "Looking in links: https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html\n",
            "Collecting kaolin==0.17.0\n",
            "  Downloading https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121/kaolin-0.17.0-cp310-cp310-linux_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipycanvas (from kaolin==0.17.0)\n",
            "  Downloading ipycanvas-0.13.3-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: ipyevents in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (2.0.2)\n",
            "Requirement already satisfied: jupyter-client<8 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (6.1.12)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (3.1.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (6.3.3)\n",
            "Collecting comm>=0.1.3 (from kaolin==0.17.0)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting usd-core (from kaolin==0.17.0)\n",
            "  Downloading usd_core-24.11-cp310-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.26.4)\n",
            "Collecting pybind11 (from kaolin==0.17.0)\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (11.1.0)\n",
            "Requirement already satisfied: tqdm>=4.51.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.13.1)\n",
            "Collecting pygltflib (from kaolin==0.17.0)\n",
            "  Downloading pygltflib-1.16.3.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting warp-lang (from kaolin==0.17.0)\n",
            "  Downloading warp_lang-1.5.1-py3-none-manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4 in /usr/local/lib/python3.10/dist-packages (from comm>=0.1.3->kaolin==0.17.0) (5.7.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (2.8.2)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (1.9.0)\n",
            "Requirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.10/dist-packages (from ipycanvas->kaolin==0.17.0) (7.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython->kaolin==0.17.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (4.9.0)\n",
            "Collecting dataclasses-json>=0.0.25 (from pygltflib->kaolin==0.17.0)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from pygltflib->kaolin==0.17.0) (1.2.15)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0)\n",
            "  Downloading marshmallow-3.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.0.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->kaolin==0.17.0) (0.8.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask->kaolin==0.17.0) (3.0.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.0->jupyter-client<8->kaolin==0.17.0) (4.3.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->kaolin==0.17.0) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kaolin==0.17.0) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client<8->kaolin==0.17.0) (1.17.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pygltflib->kaolin==0.17.0) (1.17.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (24.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (4.12.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (6.5.5)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (7.16.5)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.1.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.1.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (4.23.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (0.22.3)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (1.2.2)\n",
            "Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading ipycanvas-0.13.3-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading usd_core-24.11-cp310-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.4/25.4 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading warp_lang-1.5.1-py3-none-manylinux2014_x86_64.whl (84.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.25.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pygltflib\n",
            "  Building wheel for pygltflib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygltflib: filename=pygltflib-1.16.3-py3-none-any.whl size=27408 sha256=c1fa8a1ac8516522c3e9cbd1b2a4899062d15a632c7d7665b4b91c705e8d2a57\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/4a/cc/0d166b319ddda5007d0dfa6087346a30c4713b0fdaeaeff304\n",
            "Successfully built pygltflib\n",
            "Installing collected packages: warp-lang, usd-core, pybind11, mypy-extensions, marshmallow, jedi, comm, typing-inspect, dataclasses-json, pygltflib, ipycanvas, kaolin\n",
            "Successfully installed comm-0.2.2 dataclasses-json-0.6.7 ipycanvas-0.13.3 jedi-0.19.2 kaolin-0.17.0 marshmallow-3.25.0 mypy-extensions-1.0.0 pybind11-2.13.6 pygltflib-1.16.3 typing-inspect-0.9.0 usd-core-24.11 warp-lang-1.5.1\n",
            "Collecting open-clip-torch\n",
            "  Downloading open_clip_torch-2.30.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (0.20.1+cu121)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (2024.11.6)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (6.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (0.5.1)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open-clip-torch) (1.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open-clip-torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->open-clip-torch) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open-clip-torch) (0.2.13)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open-clip-torch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open-clip-torch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open-clip-torch) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open-clip-torch) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open-clip-torch) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open-clip-torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open-clip-torch) (2024.12.14)\n",
            "Downloading open_clip_torch-2.30.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: open-clip-torch\n",
            "Successfully installed open-clip-torch-2.30.0\n",
            "Collecting open3d\n",
            "  Downloading open3d-0.19.0-cp310-cp310-manylinux_2_31_x86_64.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.26.4)\n",
            "Collecting dash>=2.6.0 (from open3d)\n",
            "  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.1.3)\n",
            "Requirement already satisfied: flask>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.1.0)\n",
            "Requirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.10.4)\n",
            "Collecting configargparse (from open3d)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting ipywidgets>=8.0.4 (from open3d)\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting addict (from open3d)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (11.1.0)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.10.0)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.2.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.67.1)\n",
            "Collecting pyquaternion (from open3d)\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting flask>=3.0.0 (from open3d)\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting werkzeug>=3.0.0 (from open3d)\n",
            "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\n",
            "Collecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.32.3)\n",
            "Collecting retrying (from dash>=2.6.0->open3d)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (75.1.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask>=3.0.0->open3d) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask>=3.0.0->open3d) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
            "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=8.0.4->open3d)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=3.0.0->open3d) (3.0.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.22.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.6)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (9.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.17.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.12.14)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\n",
            "Downloading open3d-0.19.0-cp310-cp310-manylinux_2_31_x86_64.whl (447.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.7/447.7 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Downloading flask-3.0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, addict, widgetsnbextension, werkzeug, retrying, pyquaternion, configargparse, flask, ipywidgets, dash, open3d\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.10\n",
            "    Uninstalling widgetsnbextension-3.6.10:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.10\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: flask\n",
            "    Found existing installation: Flask 3.1.0\n",
            "    Uninstalling Flask-3.1.0:\n",
            "      Successfully uninstalled Flask-3.1.0\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed addict-2.4.0 configargparse-1.7 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 flask-3.0.3 ipywidgets-8.1.5 open3d-0.19.0 pyquaternion-0.9.9 retrying-1.3.4 werkzeug-3.0.6 widgetsnbextension-4.0.13\n",
            "Cloning into 'AML_group'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 119 (delta 55), reused 49 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (119/119), 2.76 MiB | 13.45 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n",
            "/content/AML_group\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/CLIP.git\n",
        "!pip install kaolin==0.17.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html\n",
        "!pip install open-clip-torch\n",
        "\n",
        "\n",
        "!pip install open3d\n",
        "\n",
        "\n",
        "!git clone https://github.com/AlesCarl/AML_group.git\n",
        "%cd AML_group\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-tLaxIg3mdSj"
      },
      "outputs": [],
      "source": [
        "import clip\n",
        "import copy\n",
        "import json\n",
        "import kaolin as kal\n",
        "import kaolin.ops.mesh\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import open_clip\n",
        "import open3d as o3d\n",
        "\n",
        "\n",
        "from itertools import permutations, product\n",
        "from Normalization import MeshNormalizer\n",
        "\n",
        "\n",
        "from mesh import Mesh\n",
        "from pathlib import Path\n",
        "from render import Renderer\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import grad\n",
        "from torchvision import transforms\n",
        "from utils import device, color_mesh\n",
        "\n",
        "class NeuralHighlighter(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(NeuralHighlighter, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "        for i in range(num_layers):\n",
        "            layers.append(nn.Linear(input_dim if i == 0 else hidden_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.LayerNorm([hidden_dim]))\n",
        "\n",
        "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
        "        layers.append(nn.Softmax(dim=1))\n",
        "\n",
        "        self.mlp = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.mlp:\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_clip_model(clip_model):\n",
        "    device = 'cuda'\n",
        "    model, preprocess = clip.load(clip_model, device=device) # jit = True for better perfomance\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "# ================== HELPER FUNCTIONS =============================\n",
        "def save_final_results(log_dir, name, mesh, mlp, vertices, colors, render, background):\n",
        "    mlp.eval()\n",
        "    with torch.no_grad():\n",
        "        probs = mlp(vertices)\n",
        "        max_idx = torch.argmax(probs, 1, keepdim=True)\n",
        "        # for renders\n",
        "        one_hot = torch.zeros(probs.shape).to(device)\n",
        "        one_hot = one_hot.scatter_(1, max_idx, 1)\n",
        "        sampled_mesh = mesh\n",
        "\n",
        "        highlight = torch.tensor([204, 255, 0]).to(device)\n",
        "        gray = torch.tensor([180, 180, 180]).to(device)\n",
        "        colors = torch.stack((highlight/255, gray/255)).to(device)\n",
        "        color_mesh(one_hot, sampled_mesh, colors)\n",
        "        rendered_images, _, _ = render.render_views(sampled_mesh, num_views=5,\n",
        "                                                                        show=False,\n",
        "                                                                        center_azim=0,\n",
        "                                                                        center_elev=0,\n",
        "                                                                        std=1,\n",
        "                                                                        return_views=True,\n",
        "                                                                        lighting=True,\n",
        "                                                                        background=background)\n",
        "        # for mesh\n",
        "        final_color = torch.zeros(vertices.shape[0], 3).to(device)\n",
        "        final_color = torch.where(max_idx==0, highlight, gray)\n",
        "        mesh.export(os.path.join(log_dir, f\"{name}.ply\"), extension=\"ply\", color=final_color)\n",
        "        save_renders(log_dir, 0, rendered_images, name='final_render.jpg')\n",
        "\n",
        "\n",
        "def clip_loss(n_augs, rendered_images, encoded_text, clip_transform, augment_transform, clip_model):\n",
        "\n",
        "    if n_augs == 0:\n",
        "        clip_image = clip_transform(rendered_images)\n",
        "        encoded_renders = clip_model.encode_image(clip_image)\n",
        "        encoded_renders = encoded_renders / encoded_renders.norm(dim=1, keepdim=True)\n",
        "        if encoded_text.shape[0] > 1:\n",
        "            loss = torch.cosine_similarity(torch.mean(encoded_renders, dim=0),\n",
        "                                                torch.mean(encoded_text, dim=0), dim=0)\n",
        "        else:\n",
        "            loss = torch.cosine_similarity(torch.mean(encoded_renders, dim=0, keepdim=True),\n",
        "                                                encoded_text)\n",
        "    elif n_augs > 0:\n",
        "        loss = 0.0\n",
        "        for _ in range(n_augs):\n",
        "            augmented_image = augment_transform(rendered_images)\n",
        "            encoded_renders = clip_model.encode_image(augmented_image)\n",
        "            if encoded_text.shape[0] > 1:\n",
        "                loss -= torch.cosine_similarity(torch.mean(encoded_renders, dim=0),\n",
        "                                                    torch.mean(encoded_text, dim=0), dim=0)\n",
        "            else:\n",
        "                loss -= torch.cosine_similarity(torch.mean(encoded_renders, dim=0, keepdim=True),\n",
        "                                                    encoded_text)\n",
        "    return loss\n",
        "    # \"1-loss\" removed -> now best value in output is -1\n",
        "\n",
        "def save_renders(dir, i, rendered_images, name=None):\n",
        "    if name is not None:\n",
        "        torchvision.utils.save_image(rendered_images, os.path.join(dir, name))\n",
        "    else:\n",
        "        torchvision.utils.save_image(rendered_images, os.path.join(dir, 'renders/iter_{}.jpg'.format(i)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53FxBU81mdSj",
        "outputId": "d81c98b0-cecd-4947-fc5b-00bd89a3132a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1000 [00:01<28:29,  1.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: -0.2398681640625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 101/1000 [00:22<03:45,  3.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: -0.30198974609375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 201/1000 [00:43<02:49,  4.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: -0.304666748046875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 301/1000 [01:04<02:28,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: -0.30861328125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 401/1000 [01:27<02:08,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: -0.3209716796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 501/1000 [01:48<01:47,  4.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: -0.323033447265625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 601/1000 [02:10<01:29,  4.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: -0.32206787109375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 701/1000 [02:32<01:05,  4.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: -0.327919921875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 801/1000 [02:53<00:44,  4.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: -0.3236083984375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 901/1000 [03:15<00:21,  4.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 100 CLIP score: -0.319642333984375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [03:37<00:00,  4.60it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected str, bytes or os.PathLike object, not builtin_function_or_method",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-130adcdddab7>\u001b[0m in \u001b[0;36m<cell line: 127>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# Save prompts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not builtin_function_or_method"
          ]
        }
      ],
      "source": [
        "# Constrain most sources of randomness\n",
        "# (some torch backwards functions within CLIP are non-determinstic)\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "render_res = 224\n",
        "n_iter = 1000\n",
        "res = 224\n",
        "obj_path = 'data/horse.obj' # 'APPROXIMATE.obj' if we want to test the point cloud to mesh conversion\n",
        "output_dir = './output/'\n",
        "clip_model = 'ViT-L/14'\n",
        "\n",
        "input_dim = 3\n",
        "hidden_dim = 256\n",
        "output_dim = 2\n",
        "\n",
        "# Hyper-parameters\n",
        "learning_rate = 0.0001\n",
        "n_layers = 3 # depth 4\n",
        "n_views = 3 # 5\n",
        "n_augs = 1 # 4\n",
        "\n",
        "Path(os.path.join(output_dir, 'renders')).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "objbase, extension = os.path.splitext(os.path.basename(obj_path))\n",
        "\n",
        "render = Renderer(dim=(render_res, render_res))\n",
        "mesh = Mesh(obj_path)\n",
        "MeshNormalizer(mesh)()\n",
        "\n",
        "\n",
        "### --\n",
        "\n",
        "# Initialize variables\n",
        "background = torch.tensor((1., 1., 1.)).to(device)\n",
        "\n",
        "log_dir = output_dir\n",
        "\n",
        "\n",
        "# CLIP and augmentation transform\n",
        "clip_normalizer = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "clip_transform = transforms.Compose([\n",
        "    transforms.Resize((res, res)),\n",
        "    clip_normalizer\n",
        "])\n",
        "augment_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(res, scale=(1, 1)),\n",
        "    transforms.RandomPerspective(fill=1, p=0.8, distortion_scale=0.5),\n",
        "    clip_normalizer\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# MLP Settings\n",
        "mlp = NeuralHighlighter(input_dim, hidden_dim, output_dim, n_layers).to(device)\n",
        "optim = torch.optim.Adam(mlp.parameters(), learning_rate)\n",
        "\n",
        "# list of possible colors\n",
        "rgb_to_color = {(204/255, 1., 0.): \"highlighter\", (180/255, 180/255, 180/255): \"gray\"}\n",
        "color_to_rgb = {\"highlighter\": [204/255, 1., 0.], \"gray\": [180/255, 180/255, 180/255]}\n",
        "full_colors = [[204/255, 1., 0.], [180/255, 180/255, 180/255]]\n",
        "colors = torch.tensor(full_colors).to(device)\n",
        "\n",
        "\n",
        "# --- Prompt ---\n",
        "# encode prompt with CLIP\n",
        "model = get_clip_model(clip_model)\n",
        "\n",
        "known_object = 'horse'\n",
        "classes = 'Shoes'\n",
        "\n",
        "\n",
        "prompt = \"A 3D render of a gray {} with highlighted {}\".format(known_object, classes)\n",
        "with torch.no_grad():\n",
        "    prompt_token = clip.tokenize([prompt]).to(device)\n",
        "    encoded_text = model.encode_text(prompt_token)\n",
        "    encoded_text = encoded_text / encoded_text.norm(dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "vertices = copy.deepcopy(mesh.vertices)\n",
        "\n",
        "losses = []\n",
        "\n",
        "# Optimization loop\n",
        "for i in tqdm(range(n_iter)):\n",
        "    optim.zero_grad()\n",
        "\n",
        "    # predict highlight probabilities\n",
        "    pred_class = mlp(vertices)\n",
        "\n",
        "    # color and render mesh\n",
        "    sampled_mesh = mesh\n",
        "    color_mesh(pred_class, sampled_mesh, colors)\n",
        "    rendered_images, elev, azim = render.render_views(sampled_mesh, num_views=n_views,\n",
        "                                                            show=False,\n",
        "                                                            center_azim=0,\n",
        "                                                            center_elev=0,\n",
        "                                                            std=1,\n",
        "                                                            return_views=True,\n",
        "                                                            lighting=True,\n",
        "                                                            background=background)\n",
        "\n",
        "    # Calculate CLIP Loss\n",
        "    loss = clip_loss(n_augs, rendered_images, encoded_text, clip_transform, augment_transform, model)\n",
        "    loss.backward(retain_graph=True)\n",
        "\n",
        "    optim.step()\n",
        "\n",
        "    # update variables + record loss\n",
        "    with torch.no_grad():\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    # report results\n",
        "    if i % 100 == 0:\n",
        "        print(\"Last 100 CLIP score: {}\".format(np.mean(losses[-100:])))\n",
        "        save_renders(log_dir, i, rendered_images)\n",
        "        with open(os.path.join(log_dir, \"training_info.txt\"), \"a\") as f:\n",
        "            f.write(f\"For iteration {i}... Prompt: {prompt}, Last 100 avg CLIP score: {np.mean(losses[-100:])}, CLIP score {losses[-1]}\\n\")\n",
        "\n",
        "\n",
        "# save results\n",
        "save_final_results(log_dir, 'Primo test', mesh, mlp, vertices, colors, render, background)\n",
        "\n",
        "# Save prompts\n",
        "with open(os.path.join(dir, prompt), \"w\") as f:\n",
        "    f.write('')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "P9tTHppoKMeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb2d7e3-250c-45d8-d7df-46fc0b343646"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorso del file OBJ\n",
        "obj_path = 'data/horse.obj'\n",
        "\n",
        "# Funzione per caricare la mesh come TriangleMesh\n",
        "def load_obj_as_triangle_mesh(obj_path):\n",
        "    # Carica il file .obj\n",
        "    mesh = o3d.io.read_triangle_mesh(obj_path)\n",
        "    if mesh.is_empty():\n",
        "        raise ValueError(f\"La mesh nel file {obj_path} non è stata caricata correttamente.\")\n",
        "    return mesh\n",
        "\n",
        "# Carica la mesh\n",
        "mesh = load_obj_as_triangle_mesh(obj_path)\n",
        "\n",
        "# Converte la mesh in una point cloud campionando punti uniformemente\n",
        "pcd = mesh.sample_points_uniformly(2048)\n",
        "\n",
        "# Imposta il colore nero per tutti i punti\n",
        "pcd.colors = o3d.utility.Vector3dVector(np.zeros((len(pcd.points), 3)))  # Colore nero: [0, 0, 0]\n",
        "\n",
        "\n",
        "# Esporta la point cloud in formato PLY\n",
        "# o3d.io.write_point_cloud(\"candle_PC.ply\", pcd)"
      ],
      "metadata": {
        "id": "kFSUF3vsa1a2",
        "collapsed": true
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HtJalqZNHcmE",
        "outputId": "a2edb63e-2b31-441a-d3ab-eb9765353ddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Open3D DEBUG] Input Points / Samples: 2048 / 2038\n",
            "[Open3D DEBUG] #   Got kernel density: 0.01277017593383789 (s), 3829.7890625 (MB) / 3829.7890625 (MB) / 3829 (MB)\n",
            "[Open3D DEBUG] #     Got normal field: 0.008168935775756836 (s), 3831.078125 (MB) / 3831.078125 (MB) / 3831 (MB)\n",
            "[Open3D DEBUG] Point weight / Estimated Area: 5.874402e-04 / 1.203078e+00\n",
            "[Open3D DEBUG] #       Finalized tree: 0.024731159210205078 (s), 3831.3359375 (MB) / 3831.3359375 (MB) / 3831 (MB)\n",
            "[Open3D DEBUG] #  Set FEM constraints: 0.1672039031982422 (s), 3831.3359375 (MB) / 3831.3359375 (MB) / 3831 (MB)\n",
            "[Open3D DEBUG] #Set point constraints: 0.00595402717590332 (s), 3831.3359375 (MB) / 3831.3359375 (MB) / 3831 (MB)\n",
            "[Open3D DEBUG] Leaf Nodes / Active Nodes / Ghost Nodes: 153140 / 85672 / 89345\n",
            "[Open3D DEBUG] Memory Usage: 3831.336 MB\n",
            "[Open3D DEBUG] # Linear system solved: 0.13187098503112793 (s), 3831.3359375 (MB) / 3831.3359375 (MB) / 3831 (MB)\n",
            "[Open3D DEBUG] Got average: 0.00551605224609375 (s), 3831.3359375 (MB) / 3831.3359375 (MB) / 3831 (MB)\n",
            "[Open3D DEBUG] Iso-Value: 5.054864e-01 = 1.035236e+03 / 2.048000e+03\n",
            "[Open3D DEBUG] #          Total Solve:       0.9 (s),    3831.6 (MB)\n",
            "TriangleMesh with 5474 points and 10940 triangles.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "execution_count": 28,
      "source": [
        "# Point cloud to mesh\n",
        "\n",
        "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30))\n",
        "\n",
        "with o3d.utility.VerbosityContextManager(\n",
        "        o3d.utility.VerbosityLevel.Debug) as cm:\n",
        "    mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
        "        pcd, depth=9)\n",
        "print(mesh)\n",
        "\n",
        "o3d.io.write_triangle_mesh(\"APPROXIMATE.obj\", mesh)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 part"
      ],
      "metadata": {
        "id": "qqRzSRxrq-F8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transforms3d\n",
        "\n",
        "\n",
        "from transforms3d.quaternions import quat2mat\n",
        "from transforms3d.euler import euler2mat\n",
        "\n",
        "\n",
        "\n",
        "def random_rotation_matrix():\n",
        "    rand = np.random.rand(3)\n",
        "    r1 = np.sqrt(1.0 - rand[0])\n",
        "    r2 = np.sqrt(rand[0])\n",
        "    pi2 = np.pi * 2.0\n",
        "    t1 = pi2 * rand[1]\n",
        "    t2 = pi2 * rand[2]\n",
        "    q = np.array([np.cos(t2)*r2, np.sin(t1)*r1, np.cos(t1)*r1, np.sin(t2)*r2])\n",
        "    return quat2mat(q)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def rotate_point_cloud_SO3(batch_data):\n",
        "    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n",
        "    for k in range(batch_data.shape[0]):\n",
        "        rotation_matrix = random_rotation_matrix()\n",
        "        shape_pc = batch_data[k, ...]\n",
        "        rotated_data[k, ...] = (\n",
        "            np.matmul(rotation_matrix, shape_pc.reshape((-1, 3)).T)).T\n",
        "    return rotated_data\n",
        "\n",
        "\n",
        "def rotate_point_cloud_y(batch_data):\n",
        "\n",
        "    rotated_data = np.zeros(batch_data.shape, dtype=np.float32)\n",
        "    for k in range(batch_data.shape[0]):\n",
        "        rotation_angle = np.random.uniform() * 2 * np.pi\n",
        "        rotation_matrix = euler2mat(0, rotation_angle, 0)\n",
        "        shape_pc = batch_data[k, ...]\n",
        "        rotated_data[k, ...] = (\n",
        "            np.matmul(rotation_matrix, shape_pc.reshape((-1, 3)).T)).T\n",
        "    return rotated_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9szcsLJcSU-",
        "outputId": "d239753b-3c1d-4d5a-9254-51e9e765ab5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transforms3d in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from transforms3d) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import join as opj\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import h5py\n",
        "import json\n",
        "import pickle as pkl\n",
        "\n",
        "\n",
        "def pc_normalize(pc):\n",
        "    centroid = np.mean(pc, axis=0)\n",
        "    pc = pc - centroid\n",
        "    m = np.max(np.sqrt(np.sum(pc**2, axis=1)))\n",
        "    pc = pc / m\n",
        "    return pc, centroid, m\n",
        "\n",
        "\n",
        "class AffordNetDataset(Dataset):\n",
        "    def __init__(self, data_dir, split):\n",
        "        super().__init__()\n",
        "        self.data_dir = data_dir\n",
        "        self.split = split\n",
        "\n",
        "        self.load_data()\n",
        "\n",
        "        self.affordance = self.all_data[0][\"affordance\"]\n",
        "\n",
        "        return\n",
        "\n",
        "    def load_data(self):\n",
        "     self.all_data = []\n",
        "     with open(opj(self.data_dir, 'full_shape_%s_data.pkl' % self.split), 'rb') as f:\n",
        "        temp_data = pkl.load(f)\n",
        "     for index, info in enumerate(temp_data):\n",
        "        if info[\"semantic class\"] == \"Bowl\":  # Filtra solo gli oggetti \"BOWL\"\n",
        "            temp_info = {}\n",
        "            temp_info[\"shape_id\"] = info[\"shape_id\"]\n",
        "            temp_info[\"semantic class\"] = info[\"semantic class\"]\n",
        "            temp_info[\"affordance\"] = info[\"affordance\"]\n",
        "            temp_info[\"data_info\"] = info[\"full_shape\"] # vertici\n",
        "            self.all_data.append(temp_info)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        data_dict = self.all_data[index]\n",
        "        modelid = data_dict[\"shape_id\"]\n",
        "        modelcat = data_dict[\"semantic class\"]\n",
        "\n",
        "        data_info = data_dict[\"data_info\"]\n",
        "        model_data = data_info[\"coordinate\"].astype(np.float32)\n",
        "        labels = data_info[\"label\"]\n",
        "        for aff in self.affordance:\n",
        "            temp = labels[aff].astype(np.float32).reshape(-1, 1)\n",
        "            model_data = np.concatenate((model_data, temp), axis=1)\n",
        "\n",
        "        datas = model_data[:, :3]\n",
        "        targets = model_data[:, 3:]\n",
        "\n",
        "        datas, _, _ = pc_normalize(datas)\n",
        "\n",
        "        return datas, datas, targets, modelid, modelcat\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_data)"
      ],
      "metadata": {
        "id": "GMWezA4kbbvl"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "def build_dataset(data_dir, test=False):\n",
        "    test_set = AffordNetDataset( data_dir, 'train')\n",
        "    val_set = AffordNetDataset( data_dir, 'val')\n",
        "\n",
        "     # 5 campioni per il VAL set\n",
        "    val_indices = list(range(min(5, len(val_set))))\n",
        "    val_set = Subset(val_set, val_indices)\n",
        "\n",
        "    # 10 campioni per il test set\n",
        "    test_indices = list(range(min(10, len(test_set))))\n",
        "    test_set = Subset(test_set, test_indices)\n",
        "\n",
        "    dataset_dict = dict( val_set=val_set, test_set=test_set)\n",
        "    return dataset_dict\n",
        "\n",
        "\n",
        "def build_loader(dataset_dict):\n",
        "    val_set = dataset_dict[\"val_set\"]\n",
        "    test_set = dataset_dict[\"test_set\"]\n",
        "\n",
        "    batch_size_factor = 1\n",
        "\n",
        "\n",
        "    test_loader = DataLoader(test_set, batch_size=8, ## occhio qui\n",
        "                              shuffle=True, drop_last=True, num_workers=8)\n",
        "\n",
        "    val_loader = DataLoader(val_set, batch_size=1,\n",
        "                            shuffle=False, num_workers=8, drop_last=False)\n",
        "    loader_dict = dict(\n",
        "        val_loader=val_loader,\n",
        "        test_loader=test_loader ,\n",
        "    )\n",
        "\n",
        "    return loader_dict"
      ],
      "metadata": {
        "id": "RaLjnrIucF8x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from os.path import join as opj\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import average_precision_score, f1_score, roc_auc_score\n",
        "\n",
        "\n",
        "def evaluation(model, test_loader, affordance):\n",
        "    results = torch.zeros(\n",
        "        (len(test_loader), 2048, len(affordance)))\n",
        "    targets = torch.zeros(\n",
        "        (len(test_loader), 2048, len(affordance)))\n",
        "    coordinate = np.zeros((0, 2048, 3))\n",
        "    modelids = []\n",
        "    modelcats = []\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        total_L2distance = 0\n",
        "        count = 0.0\n",
        "        for i,  temp_data in tqdm(enumerate(test_loader), total=len(test_loader), smoothing=0.9):\n",
        "\n",
        "            # modelcat identifies the category of the 3d model we are passing to our model\n",
        "            data, data1, label, modelid, modelcat = temp_data\n",
        "\n",
        "            data, label = data.float().cuda(), label.float().cuda()\n",
        "            data = data.permute(0, 2, 1)\n",
        "            batch_size = data.size()[0]\n",
        "            num_point = data.size()[2]\n",
        "            count += batch_size * num_point\n",
        "            afford_pred = torch.sigmoid(model(data))\n",
        "            afford_pred = afford_pred.permute(0, 2, 1).contiguous()\n",
        "            L2distance = torch.sum(\n",
        "                torch.pow(label-afford_pred, 2), dim=(0, 1))\n",
        "            total_L2distance += L2distance\n",
        "            score = afford_pred.squeeze()\n",
        "            target_score = label.squeeze()\n",
        "            results[i, :, :] = score\n",
        "            targets[i, :, :] = target_score\n",
        "            modelids.append(modelid[0])\n",
        "            modelcats.append(modelcat[0])\n",
        "\n",
        "    results = results.detach().cpu().numpy()\n",
        "    targets = targets.detach().cpu().numpy()\n",
        "    IOU = np.zeros((targets.shape[0], targets.shape[2]))\n",
        "    targets = targets >= 0.5\n",
        "    targets = targets.astype(int)\n",
        "\n",
        "    IOU_thres = np.linspace(0, 1, 20)\n",
        "    for i in range(IOU.shape[0]):\n",
        "        t = targets[i, :, :]\n",
        "        p = results[i, :, :]\n",
        "        for j in range(t.shape[1]):\n",
        "            t_true = t[:, j]\n",
        "            p_score = p[:, j]\n",
        "            if np.sum(t_true) == 0:\n",
        "                IOU[i, j] = np.nan\n",
        "            else:\n",
        "                p_mask = (p_score > 0.5).astype(int)\n",
        "                temp_iou = []\n",
        "                for thre in IOU_thres:\n",
        "                    p_mask = (p_score >= thre).astype(int)\n",
        "                    intersect = np.sum(p_mask & t_true)\n",
        "                    union = np.sum(p_mask | t_true)\n",
        "                    temp_iou.append(1.*intersect/union)\n",
        "                temp_iou = np.array(temp_iou)\n",
        "                aiou = np.mean(temp_iou)\n",
        "                IOU[i, j] = aiou\n",
        "\n",
        "    IOU = np.nanmean(IOU, axis=0)\n",
        "\n",
        "    outstr = 'Test :: test maIOU: %.6f' % (\n",
        "        np.mean(IOU))\n",
        "\n",
        "    return np.mean(IOU)"
      ],
      "metadata": {
        "id": "b7bndVjRaA5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = '/content/drive/My Drive/full-shape'\n",
        "\n",
        "dataset = build_dataset(dataset_dir)\n",
        "\n",
        "loader = build_loader(dataset)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "48VXxFvQdSjc"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumendo che `loader[\"val_loader\"]` sia il DataLoader principale\n",
        "for batch in loader[\"val_loader\"]:\n",
        "    # Estraggo il primo elemento del batch\n",
        "    datas, prova, targets, modelid, modelcat = batch\n",
        "\n",
        "    # Stampare la \"affordance\" dal primo elemento\n",
        "    print(\"Affordance:\", prova[0])\n",
        "    break  # Uscire dopo il primo batch\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "u-IljHvim6e4",
        "outputId": "6d114e39-e64e-4fe8-e283-3b33c6c0f4ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Affordance: tensor([[ 0.2516, -0.0257,  0.2042],\n",
            "        [-0.6823,  0.6966, -0.2069],\n",
            "        [-0.6833, -0.5620, -0.2057],\n",
            "        ...,\n",
            "        [-0.3412,  0.1812,  0.2042],\n",
            "        [-0.0785, -0.5747, -0.1798],\n",
            "        [ 0.3324, -0.5747,  0.1575]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import open3d as o3d\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "bQ3NykWYE-fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conversione point cloud to mesh:\n",
        "\n",
        "def pointToMesh(data ):\n",
        "\n",
        "    single_data = data[0].cpu().numpy()     # shape [N, 3]\n",
        "    single_target = targets[0].cpu().numpy() # shape [N, num_affordances].     PER COSA LO USA\n",
        "\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(single_data)\n",
        "\n",
        "    # new_points = np.random.normal(loc=np.array(pcd.points), scale=0.005, size=(len(pcd.points), 3))\n",
        "    # dense_pcd = o3d.geometry.PointCloud()\n",
        "    # dense_pcd.points = o3d.utility.Vector3dVector(np.vstack((np.array(pcd.points), new_points)))\n",
        "\n",
        "    # (Opzionale) Se hai colori (o label) associati a ogni punto, potresti\n",
        "    #  impostarli come pcd.colors, ma qui li useremo solo come reference.\n",
        "\n",
        "    # Stima delle normali\n",
        "    pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(\n",
        "        radius=0.08,  # Raggio per la stima delle normali, aumentalo se i punti sono più distanti\n",
        "        max_nn=50     # Numero massimo di vicini per stimare la normale\n",
        "    ))\n",
        "\n",
        "    # Orienta le normali in modo consistente\n",
        "    pcd.orient_normals_consistent_tangent_plane(k=30)\n",
        "\n",
        "    # Calcola la distanza media tra i punti per ottimizzare il raggio della sfera\n",
        "    distances = pcd.compute_nearest_neighbor_distance()\n",
        "    mean_distance = np.mean(distances)\n",
        "    print(f\"Distanza media tra i punti: {mean_distance:.4f}\")\n",
        "\n",
        "\n",
        "    # Imposta i raggi per Ball Pivoting basandoti sulla densità della point-cloud\n",
        "    radii = [mean_distance * 1.5, mean_distance * 2, mean_distance * 2.5]\n",
        "\n",
        "    # Ricostruzione con Ball Pivoting\n",
        "    mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(\n",
        "        pcd, o3d.utility.DoubleVector(radii)\n",
        "    )\n",
        "\n",
        "    # (Opzionale) Liscia la mesh per rimuovere artefatti\n",
        "    mesh = mesh.filter_smooth_laplacian(number_of_iterations=5)\n",
        "\n",
        "    # Salva e visualizza la mesh\n",
        "    o3d.io.write_triangle_mesh(\"bowl_mesh_ball_pivoting.obj\", mesh)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Point cloud to mesh"
      ],
      "metadata": {
        "id": "fBayJ77NDNZd"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FUNZIONE"
      ],
      "metadata": {
        "id": "Ihm5O9Gho7bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def optimize (vertex, targets , modelCat):\n",
        "\n",
        "    pointToMesh(vertex) #\n",
        "\n",
        "\n",
        "    seed = 42\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "\n",
        "    render_res = 224\n",
        "    n_iter = 1000\n",
        "    res = 224\n",
        "    obj_path = 'data.obj'\n",
        "    output_dir = './output/'\n",
        "    clip_model = 'ViT-L/14'\n",
        "\n",
        "    input_dim = 3\n",
        "    hidden_dim = 256\n",
        "    output_dim = 2\n",
        "\n",
        "    # Hyper-parameters\n",
        "    learning_rate = 0.0001\n",
        "    n_layers = 4 # depth 4\n",
        "    n_views = 3 # 5\n",
        "    n_augs = 4 # 4\n",
        "\n",
        "    Path(os.path.join(output_dir, 'renders')).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    objbase, extension = os.path.splitext(os.path.basename(obj_path))\n",
        "\n",
        "    render = Renderer(dim=(render_res, render_res))\n",
        "    mesh = Mesh(obj_path)\n",
        "    MeshNormalizer(mesh)()\n",
        "\n",
        "\n",
        "\n",
        "    # Initialize variables\n",
        "    background = torch.tensor((1., 1., 1.)).to(device)\n",
        "\n",
        "    log_dir = output_dir\n",
        "\n",
        "\n",
        "    # CLIP and augmentation transform\n",
        "    clip_normalizer = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "    clip_transform = transforms.Compose([\n",
        "        transforms.Resize((res, res)),\n",
        "        clip_normalizer\n",
        "    ])\n",
        "    augment_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(res, scale=(1, 1)),\n",
        "        transforms.RandomPerspective(fill=1, p=0.8, distortion_scale=0.5),\n",
        "        clip_normalizer\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "    # MLP Settings\n",
        "    mlp = NeuralHighlighter(input_dim, hidden_dim, output_dim, n_layers).to(device)\n",
        "    optim = torch.optim.Adam(mlp.parameters(), learning_rate)\n",
        "\n",
        "    # list of possible colors\n",
        "    rgb_to_color = {(204/255, 1., 0.): \"highlighter\", (180/255, 180/255, 180/255): \"gray\"}\n",
        "    color_to_rgb = {\"highlighter\": [204/255, 1., 0.], \"gray\": [180/255, 180/255, 180/255]}\n",
        "    full_colors = [[204/255, 1., 0.], [180/255, 180/255, 180/255]]\n",
        "    colors = torch.tensor(full_colors).to(device)\n",
        "\n",
        "\n",
        "    # --- Prompt ---\n",
        "    # encode prompt with CLIP\n",
        "    model = get_clip_model(clip_model)\n",
        "\n",
        "    known_object = modelCat\n",
        "    classes = \"region for grasping\"  # o una affordance specifica ----- DA SISTEMARE\n",
        "\n",
        "\n",
        "    prompt = f\"A 3D render of a gray {known_object} with highlighted {classes}\"\n",
        "\n",
        "\n",
        "\n",
        "    '''\n",
        "    # Qui puoi definire i tuoi prompt CLIP\n",
        "    known_object = modelcat[0]  # per esempio 'Bag'\n",
        "    classes = \"region for grasping\"  # o una affordance specifica\n",
        "    prompt = f\"A 3D render of a gray {known_object} with highlighted {classes}\"\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "    #prompt = \"A 3D render of a gray {} with highlighted {}\".format(known_object, classes)\n",
        "    with torch.no_grad():\n",
        "        prompt_token = clip.tokenize([prompt]).to(device)\n",
        "        encoded_text = model.encode_text(prompt_token)\n",
        "        encoded_text = encoded_text / encoded_text.norm(dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "    vertices = copy.deepcopy(mesh.vertices)\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    # Optimization loop\n",
        "    for i in tqdm(range(n_iter)):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        # predict highlight probabilities\n",
        "        pred_class = mlp(vertices)\n",
        "\n",
        "        # color and render mesh\n",
        "        sampled_mesh = mesh\n",
        "        color_mesh(pred_class, sampled_mesh, colors)\n",
        "        rendered_images, elev, azim = render.render_views(sampled_mesh, num_views=n_views,\n",
        "                                                                show=False,\n",
        "                                                                center_azim=0,\n",
        "                                                                center_elev=0,\n",
        "                                                                std=1,\n",
        "                                                                return_views=True,\n",
        "                                                                lighting=True,\n",
        "                                                                background=background)\n",
        "\n",
        "        # Calculate CLIP Loss\n",
        "        loss = clip_loss(n_augs, rendered_images, encoded_text, clip_transform, augment_transform, model)\n",
        "        loss.backward(retain_graph=True)\n",
        "\n",
        "        optim.step()\n",
        "\n",
        "        # update variables + record loss\n",
        "        with torch.no_grad():\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        # report results\n",
        "        if i % 100 == 0:\n",
        "            print(\"Last 100 CLIP score: {}\".format(np.mean(losses[-100:])))\n",
        "            save_renders(log_dir, i, rendered_images)\n",
        "            with open(os.path.join(log_dir, \"training_info.txt\"), \"a\") as f:\n",
        "                f.write(f\"For iteration {i}... Prompt: {prompt}, Last 100 avg CLIP score: {np.mean(losses[-100:])}, CLIP score {losses[-1]}\\n\")\n",
        "\n",
        "\n",
        "    # save results\n",
        "    save_final_results(log_dir, 'TTest2', mesh, mlp, vertices, colors, render, background)\n",
        "\n",
        "\n",
        "    # Save prompts\n",
        "    # with open(os.path.join(dir, prompt), \"w\") as f:\n",
        "      #  f.write('')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ezLSO9xoorXo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# puo essere utile in futuro:\n",
        "\n",
        "known_object = \"Bag\"\n",
        "\n",
        "\n",
        "affordances = {\n",
        "    \"grasp\": \"where a hand can grasp it\",\n",
        "    \"push\": \"where a hand can push it\",\n",
        "    \"wrap\": \"where fingers can wrap around it\"\n",
        "}\n",
        "\n",
        "for affordance, description in affordances.items():\n",
        "    prompt = f\"A 3D render of a gray {known_object} with highlighted {description}\"\n",
        "    print(prompt)\n",
        "\n",
        "\n",
        "\n",
        "''' NOTA BENE:\n",
        "\n",
        "\n",
        "CLIP funziona bene con prompt che sembrano frasi naturali, quindi è meglio evitare descrizioni troppo tecniche o astratte come\n",
        "\"region for grasping\". Scegli formulazioni che un umano userebbe per descrivere le affordance, ad esempio \"where it can be grasped\"\n",
        "o \"graspable areas\". Questo può migliorare il risultato del tuo modello.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "eH4E0x6AXVwz",
        "outputId": "3bec4e95-9666-4749-bbce-7d6acf6b68dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'known_object' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2dfe84e15c72>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0maffordance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maffordances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"A 3D render of a gray {known_object} with highlighted {description}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'known_object' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx, batch in enumerate(loader[\"val_loader\"]):\n",
        "    # if batch_idx == 0:\n",
        "    #    continue\n",
        "    # Estraggo il primo elemento del batch\n",
        "    data, data1, targets, modelid, modelcat = batch   # con target = GT  ( area giusta da colorare )\n",
        "    pointToMesh(data) #\n",
        "    label = \"grasp\"\n",
        "\n",
        "    #optimize(data, targets,modelcat, label)\n",
        "\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "1kxAaIDayBU3",
        "outputId": "de15cc66-d38c-40fd-abcd-1c4f9cd94af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distanza media tra i punti: 0.0574\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: Failed to detect any supported platform\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW initialized for headless rendering.\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] GLFW Error: OSMesa: Library not found\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] Failed to create window\u001b[0;m\n",
            "\u001b[1;33m[Open3D WARNING] [DrawGeometries] Failed creating OpenGL window.\u001b[0;m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NrEYUN1No9fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Numero di oggetti nel validation loader\n",
        "num_val_objects = len(loader[\"val_loader\"].dataset)\n",
        "print(f\"Number of objects in val_loader: {num_val_objects}\")\n",
        "\n",
        "# Numero di oggetti nel test loader\n",
        "num_test_objects = len(loader[\"test_loader\"].dataset)\n",
        "print(f\"Number of objects in test_loader: {num_test_objects}\")\n"
      ],
      "metadata": {
        "id": "6WblDH0yFUJ8",
        "outputId": "f1eba8d4-58fa-48d8-fb79-a7bd97e2374e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of objects in val_loader: 5\n",
            "Number of objects in test_loader: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO: domani:\n",
        "\n",
        "- OTTENERE UN MESH DI QUALITA' MAGGIORE  !!"
      ],
      "metadata": {
        "id": "ewkuWeluGnWL"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}